{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b5454e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crop Suitability Prediction:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\ml_env\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCrop Suitability Prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m new_grid_conditions \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m6.5\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m suitability \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_crop_suitability\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_grid_conditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop, probability \u001b[38;5;129;01min\u001b[39;00m suitability:\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobability\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m, in \u001b[0;36mpredict_crop_suitability\u001b[1;34m(moisture, N, P, K, pH)\u001b[0m\n\u001b[0;32m     40\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[moisture, N, P, K, pH]])\n\u001b[0;32m     41\u001b[0m input_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(input_data)\n\u001b[1;32m---> 43\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(input_scaled)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     45\u001b[0m crop_probs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, crop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(le\u001b[38;5;241m.\u001b[39mclasses_):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = {\n",
    "    'Time': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48],\n",
    "    'Grid ID': [1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6],\n",
    "    'Crop': ['Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton'],\n",
    "    'Moisture': [42.3,28.5,35.6,38.2,40.1,34.2,41.8,29.1,36.2,37.9,39.8,33.9,43.1,27.9,34.9,38.5,40.4,34.5,42.6,28.7,35.8,37.6,39.5,33.6,41.5,29.3,36.5,38.8,40.7,34.8,42.9,28.3,35.7,38.3,40.2,34.3,41.7,29.2,36.3,37.8,39.9,33.8,43.2,28.8,35.5,38.6,40.5,34.6],\n",
    "    'N': [0.25,0.32,0.45,0.28,0.22,0.38,0.23,0.33,0.47,0.27,0.21,0.37,0.26,0.31,0.44,0.29,0.23,0.39,0.24,0.32,0.46,0.26,0.20,0.36,0.22,0.34,0.48,0.30,0.24,0.40,0.25,0.31,0.45,0.28,0.22,0.38,0.22,0.33,0.47,0.26,0.21,0.36,0.26,0.32,0.44,0.29,0.23,0.39],\n",
    "    'P': [0.15,0.22,0.35,0.18,0.16,0.28,0.14,0.23,0.36,0.17,0.15,0.27,0.16,0.21,0.34,0.19,0.17,0.29,0.15,0.22,0.35,0.16,0.14,0.26,0.13,0.24,0.37,0.20,0.18,0.30,0.15,0.21,0.35,0.18,0.16,0.28,0.14,0.23,0.36,0.17,0.15,0.26,0.16,0.22,0.34,0.19,0.17,0.29],\n",
    "    'K': [0.20,0.28,0.40,0.25,0.19,0.35,0.18,0.30,0.42,0.24,0.18,0.34,0.22,0.27,0.39,0.26,0.20,0.36,0.19,0.29,0.41,0.23,0.17,0.33,0.17,0.31,0.43,0.27,0.21,0.37,0.21,0.27,0.40,0.25,0.19,0.35,0.18,0.30,0.42,0.24,0.18,0.33,0.22,0.29,0.39,0.26,0.20,0.36],\n",
    "    'pH': [6.2,5.8,6.5,6.7,5.5,6.9,6.3,5.9,6.4,6.8,5.6,7.0,6.1,5.7,6.6,6.6,5.4,6.8,6.4,5.8,6.3,6.9,5.7,7.1,6.2,6.0,6.5,6.7,5.5,6.9,6.3,5.9,6.4,6.8,5.6,7.0,6.2,5.8,6.5,6.7,5.5,6.9,6.4,5.7,6.6,6.9,5.4,6.8]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Crop_Encoded'] = le.fit_transform(df['Crop'])\n",
    "\n",
    "features = ['Moisture', 'N', 'P', 'K', 'pH']\n",
    "X = df[features]\n",
    "y = df['Crop_Encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "unique_labels = np.unique(y_test)\n",
    "\n",
    "def predict_crop_suitability(moisture, N, P, K, pH):\n",
    "    # Prepare the input\n",
    "    input_data = np.array([[moisture, N, P, K, pH]])\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    predictions = model.predict(input_scaled)[0]\n",
    "    \n",
    "    crop_probs = {}\n",
    "    for i, crop in enumerate(le.classes_):\n",
    "        crop_probs[crop] = predictions[i]\n",
    "    \n",
    "    sorted_crops = sorted(crop_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_crops\n",
    "\n",
    "print(\"\\nCrop Suitability Prediction:\")\n",
    "new_grid_conditions = (40, 0.3, 0.2, 0.25, 6.5)\n",
    "suitability = predict_crop_suitability(*new_grid_conditions)\n",
    "for crop, probability in suitability:\n",
    "    print(f\"{crop}: {probability*100:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80566640",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(5,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train, \n",
    "    validation_split=0.2, \n",
    "    epochs=100, \n",
    "    batch_size=16, \n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c04811ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Crop Suitability Prediction:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\ml_env\\lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 46\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCrop Suitability Prediction:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     45\u001b[0m new_grid_conditions \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.2\u001b[39m, \u001b[38;5;241m0.25\u001b[39m, \u001b[38;5;241m6.5\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m suitability \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_crop_suitability\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_grid_conditions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m crop, probability \u001b[38;5;129;01min\u001b[39;00m suitability:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcrop\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprobability\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 34\u001b[0m, in \u001b[0;36mpredict_crop_suitability\u001b[1;34m(moisture, N, P, K, pH)\u001b[0m\n\u001b[0;32m     31\u001b[0m input_data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[moisture, N, P, K, pH]])\n\u001b[0;32m     32\u001b[0m input_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(input_data)\n\u001b[1;32m---> 34\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(input_scaled)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     36\u001b[0m crop_probs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, crop \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(le\u001b[38;5;241m.\u001b[39mclasses_):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Time': [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48],\n",
    "    'Grid ID': [1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6,1,2,3,4,5,6],\n",
    "    'Crop': ['Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton','Apple','Rice','Maize','Tomato','Potato','Cotton'],\n",
    "    'Moisture': [42.3,28.5,35.6,38.2,40.1,34.2,41.8,29.1,36.2,37.9,39.8,33.9,43.1,27.9,34.9,38.5,40.4,34.5,42.6,28.7,35.8,37.6,39.5,33.6,41.5,29.3,36.5,38.8,40.7,34.8,42.9,28.3,35.7,38.3,40.2,34.3,41.7,29.2,36.3,37.8,39.9,33.8,43.2,28.8,35.5,38.6,40.5,34.6],\n",
    "    'N': [0.25,0.32,0.45,0.28,0.22,0.38,0.23,0.33,0.47,0.27,0.21,0.37,0.26,0.31,0.44,0.29,0.23,0.39,0.24,0.32,0.46,0.26,0.20,0.36,0.22,0.34,0.48,0.30,0.24,0.40,0.25,0.31,0.45,0.28,0.22,0.38,0.22,0.33,0.47,0.26,0.21,0.36,0.26,0.32,0.44,0.29,0.23,0.39],\n",
    "    'P': [0.15,0.22,0.35,0.18,0.16,0.28,0.14,0.23,0.36,0.17,0.15,0.27,0.16,0.21,0.34,0.19,0.17,0.29,0.15,0.22,0.35,0.16,0.14,0.26,0.13,0.24,0.37,0.20,0.18,0.30,0.15,0.21,0.35,0.18,0.16,0.28,0.14,0.23,0.36,0.17,0.15,0.26,0.16,0.22,0.34,0.19,0.17,0.29],\n",
    "    'K': [0.20,0.28,0.40,0.25,0.19,0.35,0.18,0.30,0.42,0.24,0.18,0.34,0.22,0.27,0.39,0.26,0.20,0.36,0.19,0.29,0.41,0.23,0.17,0.33,0.17,0.31,0.43,0.27,0.21,0.37,0.21,0.27,0.40,0.25,0.19,0.35,0.18,0.30,0.42,0.24,0.18,0.33,0.22,0.29,0.39,0.26,0.20,0.36],\n",
    "    'pH': [6.2,5.8,6.5,6.7,5.5,6.9,6.3,5.9,6.4,6.8,5.6,7.0,6.1,5.7,6.6,6.6,5.4,6.8,6.4,5.8,6.3,6.9,5.7,7.1,6.2,6.0,6.5,6.7,5.5,6.9,6.3,5.9,6.4,6.8,5.6,7.0,6.2,5.8,6.5,6.7,5.5,6.9,6.4,5.7,6.6,6.9,5.4,6.8]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['Crop_Encoded'] = le.fit_transform(df['Crop'])\n",
    "\n",
    "features = ['Moisture', 'N', 'P', 'K', 'pH']\n",
    "X = df[features]\n",
    "y = df['Crop_Encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "unique_labels = np.unique(y_test)\n",
    "\n",
    "def predict_crop_suitability(moisture, N, P, K, pH):\n",
    "    # Prepare the input\n",
    "    input_data = np.array([[moisture, N, P, K, pH]])\n",
    "    input_scaled = scaler.transform(input_data)\n",
    "    \n",
    "    predictions = model.predict(input_scaled)[0]\n",
    "    \n",
    "    crop_probs = {}\n",
    "    for i, crop in enumerate(le.classes_):\n",
    "        crop_probs[crop] = predictions[i]\n",
    "    \n",
    "    sorted_crops = sorted(crop_probs.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    return sorted_crops\n",
    "\n",
    "print(\"\\nCrop Suitability Prediction:\")\n",
    "new_grid_conditions = (40, 0.3, 0.2, 0.25, 6.5)\n",
    "suitability = predict_crop_suitability(*new_grid_conditions)\n",
    "for crop, probability in suitability:\n",
    "    print(f\"{crop}: {probability*100:.2f}%\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/mnt/data/Crop_Database.xlsx\"\n",
    "\n",
    "# Load Sheet2 (real-time sensor values)\n",
    "df_sheet2 = pd.read_excel(file_path, sheet_name=\"Sheet2\")\n",
    "\n",
    "# Load Sheet3 (app connectivity sheet)\n",
    "df_sheet3 = pd.read_excel(file_path, sheet_name=\"Sheet3\")\n",
    "\n",
    "# Compute average values for each Grid ID from Sheet2\n",
    "avg_values = df_sheet2.groupby(\"Grid ID\")[[\"Moisture\", \"N\", \"P\", \"K\", \"pH\"]].mean().reset_index()\n",
    "\n",
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"/mnt/data/crop_model.h5\")  # Ensure to save and load your trained model properly\n",
    "\n",
    "# Encode crop labels\n",
    "crop_labels = [\"Apple\", \"Rice\", \"Maize\", \"Tomato\", \"Potato\", \"Cotton\", \"Wheat\", \"Soybean\"]  # Modify as needed\n",
    "le = LabelEncoder()\n",
    "le.fit(crop_labels)\n",
    "\n",
    "# Standardize the input features using precomputed scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(avg_values[[\"Moisture\", \"N\", \"P\", \"K\", \"pH\"]])  # Fit with avg values\n",
    "\n",
    "# Function to predict the most suitable crop\n",
    "def predict_crop_suitability(input_data):\n",
    "    input_scaled = scaler.transform([input_data])\n",
    "    predictions = model.predict(input_scaled)[0]\n",
    "    \n",
    "    # Get crop probabilities\n",
    "    crop_probs = list(zip(le.classes_, predictions))\n",
    "    \n",
    "    # Sort crops by probability in descending order\n",
    "    crop_probs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Return the crop with the highest probability\n",
    "    best_crop = crop_probs[0][0]\n",
    "    \n",
    "    return best_crop\n",
    "\n",
    "# Apply predictions to each Grid ID\n",
    "df_sheet3[\"Suitable Crop\"] = df_sheet3[\"Grid ID\"].map(\n",
    "    lambda gid: predict_crop_suitability(avg_values[avg_values[\"Grid ID\"] == gid].iloc[0, 1:].values)\n",
    ")\n",
    "\n",
    "# Save the updated file\n",
    "output_file = \"/mnt/data/Crop_Database_Updated.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine=\"xlsxwriter\") as writer:\n",
    "    df_sheet2.to_excel(writer, sheet_name=\"Sheet2\", index=False)\n",
    "    df_sheet3.to_excel(writer, sheet_name=\"Sheet3\", index=False)\n",
    "\n",
    "print(f\"Updated file saved as {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
